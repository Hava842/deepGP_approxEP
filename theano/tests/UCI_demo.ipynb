{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "Theano version: 0.9.0, base compile dir: /home/mh740/.theano\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import theano\n",
    "sys.path.append('../code/')\n",
    "import AEPDGP_net\n",
    "import time\n",
    "\n",
    "sys.path.append('/homes/mlghomes/mh740/Doubly-Stochastic-DGP/demos')\n",
    "from get_data import get_regression_data\n",
    "\n",
    "print 'Theano version: ' + theano.__version__ + ', base compile dir: ' + theano.config.base_compiledir\n",
    "# theano.config.compute_test_value = 'warn'\n",
    "theano.config.optimizer = 'None'\n",
    "# theano.exception_verbosity = 'high'\n",
    "theano.config.mode = 'FAST_RUN'\n",
    "theano.config.optimizer = 'fast_run'\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 7372, D: 8, Ns: 820\n"
     ]
    }
   ],
   "source": [
    "X, Y, Xs, Ys = get_regression_data('kin8nm', split=0)\n",
    "Y = Y.reshape((-1))\n",
    "Ys = Ys.reshape((-1))\n",
    "print 'N: {}, D: {}, Ns: {}'.format(X.shape[0], X.shape[1], Xs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<!! BUG IN FGRAPH.REPLACE OR A LISTENER !!>> <type 'exceptions.TypeError'> ('The type of the replacement must be compatible with the type of the original Variable.', Sum{acc_dtype=int64}.0, Elemwise{mul,no_inplace}.0, TensorType(int64, scalar), TensorType(bool, scalar), 'local_opt_alloc') local_opt_alloc\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_opt_alloc\n",
      "ERROR (theano.gof.opt): node: Sum{acc_dtype=int64}(Alloc.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/opt.py\", line 2022, in process_node\n",
      "    remove=remove)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py\", line 391, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py\", line 340, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/fg.py\", line 481, in replace\n",
      "    str(reason))\n",
      "TypeError: ('The type of the replacement must be compatible with the type of the original Variable.', Sum{acc_dtype=int64}.0, Elemwise{mul,no_inplace}.0, TensorType(int64, scalar), TensorType(bool, scalar), 'local_opt_alloc')\n",
      "\n",
      "<<!! BUG IN FGRAPH.REPLACE OR A LISTENER !!>> <type 'exceptions.TypeError'> ('The type of the replacement must be compatible with the type of the original Variable.', Sum{acc_dtype=int64}.0, Elemwise{mul,no_inplace}.0, TensorType(int64, scalar), TensorType(bool, scalar), 'local_opt_alloc') local_opt_alloc\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_opt_alloc\n",
      "ERROR (theano.gof.opt): node: Sum{acc_dtype=int64}(Alloc.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/opt.py\", line 2022, in process_node\n",
      "    remove=remove)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py\", line 391, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py\", line 340, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/fg.py\", line 481, in replace\n",
      "    str(reason))\n",
      "TypeError: ('The type of the replacement must be compatible with the type of the original Variable.', Sum{acc_dtype=int64}.0, Elemwise{mul,no_inplace}.0, TensorType(int64, scalar), TensorType(bool, scalar), 'local_opt_alloc')\n",
      "\n",
      "<<!! BUG IN FGRAPH.REPLACE OR A LISTENER !!>> <type 'exceptions.TypeError'> ('The type of the replacement must be compatible with the type of the original Variable.', Sum{acc_dtype=int64}.0, Elemwise{mul,no_inplace}.0, TensorType(int64, scalar), TensorType(bool, scalar), 'local_opt_alloc') local_opt_alloc\n",
      "ERROR (theano.gof.opt): Optimization failure due to: local_opt_alloc\n",
      "ERROR (theano.gof.opt): node: Sum{acc_dtype=int64}(Alloc.0)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/opt.py\", line 2022, in process_node\n",
      "    remove=remove)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py\", line 391, in replace_all_validate_remove\n",
      "    chk = fgraph.replace_all_validate(replacements, reason)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/toolbox.py\", line 340, in replace_all_validate\n",
      "    fgraph.replace(r, new_r, reason=reason, verbose=False)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gof/fg.py\", line 481, in replace\n",
      "    str(reason))\n",
      "TypeError: ('The type of the replacement must be compatible with the type of the original Variable.', Sum{acc_dtype=int64}.0, Elemwise{mul,no_inplace}.0, TensorType(int64, scalar), TensorType(bool, scalar), 'local_opt_alloc')\n",
      "\n",
      "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iter: 10, logZ: 5388.08756\n",
      "training iter: 20, logZ: 3811.29999\n",
      "training iter: 30, logZ: 3838.51347\n",
      "training iter: 40, logZ: 3140.22555\n",
      "training iter: 50, logZ: 2473.04126\n",
      "training iter: 60, logZ: 1555.78839\n",
      "training iter: 70, logZ: 967.08499\n",
      "training iter: 80, logZ: 138.48234\n",
      "training iter: 90, logZ: -554.28426\n",
      "training iter: 100, logZ: -628.21918\n",
      "training iter: 110, logZ: -1043.19466\n",
      "training iter: 120, logZ: -1701.31865\n",
      "training iter: 130, logZ: -1730.27144\n",
      "training iter: 140, logZ: -1896.38718\n",
      "training iter: 150, logZ: -1874.57777\n",
      "training iter: 160, logZ: -2401.57603\n",
      "training iter: 170, logZ: -2291.94931\n",
      "training iter: 180, logZ: -2461.41255\n",
      "training iter: 190, logZ: -2714.63945\n",
      "training iter: 200, logZ: -2662.11462\n",
      "training iter: 210, logZ: -3091.51547\n",
      "training iter: 220, logZ: -2992.74381\n",
      "training iter: 230, logZ: -2881.72595\n",
      "training iter: 240, logZ: -2899.56053\n",
      "training iter: 250, logZ: -3312.43425\n",
      "training iter: 260, logZ: -2985.08958\n",
      "training iter: 270, logZ: -3231.34242\n",
      "training iter: 280, logZ: -3185.12831\n",
      "training iter: 290, logZ: -3711.32315\n",
      "training iter: 300, logZ: -3552.76327\n",
      "training iter: 310, logZ: -3058.90608\n",
      "training iter: 320, logZ: -3551.60127\n",
      "training iter: 330, logZ: -3705.32645\n",
      "training iter: 340, logZ: -3489.23635\n",
      "training iter: 350, logZ: -3675.65887\n",
      "training iter: 360, logZ: -3776.70073\n",
      "training iter: 370, logZ: -3800.61291\n",
      "training iter: 380, logZ: -3894.63655\n",
      "training iter: 390, logZ: -4163.54116\n",
      "training iter: 400, logZ: -4233.81833\n",
      "training iter: 410, logZ: -4295.48090\n",
      "training iter: 420, logZ: -4008.64315\n",
      "training iter: 430, logZ: -3900.70217\n",
      "training iter: 440, logZ: -3918.11325\n",
      "training iter: 450, logZ: -3965.23052\n",
      "training iter: 460, logZ: -4133.74372\n",
      "training iter: 470, logZ: -4639.24768\n",
      "training iter: 480, logZ: -4423.83697\n",
      "training iter: 490, logZ: -4385.99225\n",
      "training iter: 500, logZ: -4349.22859\n",
      "training iter: 510, logZ: -4319.32374\n",
      "training iter: 520, logZ: -4106.32713\n",
      "training iter: 530, logZ: -4486.11908\n",
      "training iter: 540, logZ: -3871.87789\n",
      "training iter: 550, logZ: -4367.23758\n",
      "training iter: 560, logZ: -4267.40636\n",
      "training iter: 570, logZ: -4494.75137\n",
      "training iter: 580, logZ: -3882.31025\n",
      "training iter: 590, logZ: -4380.61836\n",
      "training iter: 600, logZ: -4579.34428\n",
      "training iter: 610, logZ: -4265.24519\n",
      "training iter: 620, logZ: -4280.54049\n",
      "training iter: 630, logZ: -4602.01885\n",
      "training iter: 640, logZ: -4534.83134\n",
      "training iter: 650, logZ: -4123.29591\n",
      "training iter: 660, logZ: -4440.67339\n",
      "training iter: 670, logZ: -4573.17204\n",
      "training iter: 680, logZ: -4824.30916\n",
      "training iter: 690, logZ: -4707.36157\n",
      "training iter: 700, logZ: -4315.81406\n",
      "training iter: 710, logZ: -4618.77658\n",
      "training iter: 720, logZ: -3949.01558\n",
      "training iter: 730, logZ: -4624.44226\n",
      "training iter: 740, logZ: -4819.65522\n",
      "training iter: 750, logZ: -4730.29714\n",
      "training iter: 760, logZ: -4703.83503\n",
      "training iter: 770, logZ: -4669.48093\n",
      "training iter: 780, logZ: -4732.37163\n",
      "training iter: 790, logZ: -4657.23245\n",
      "training iter: 800, logZ: -4653.45045\n",
      "training iter: 810, logZ: -4543.37749\n",
      "training iter: 820, logZ: -4557.89790\n",
      "training iter: 830, logZ: -4762.73649\n",
      "training iter: 840, logZ: -5053.24548\n",
      "training iter: 850, logZ: -4704.09712\n",
      "training iter: 860, logZ: -4581.71710\n",
      "training iter: 870, logZ: -4930.99911\n",
      "training iter: 880, logZ: -4706.16823\n",
      "training iter: 890, logZ: -4403.19650\n",
      "training iter: 900, logZ: -4635.60344\n",
      "training iter: 910, logZ: -5009.72901\n",
      "training iter: 920, logZ: -4589.00300\n",
      "training iter: 930, logZ: -5064.23649\n",
      "training iter: 940, logZ: -4907.46950\n",
      "training iter: 950, logZ: -4716.72334\n",
      "training iter: 960, logZ: -4724.12362\n",
      "training iter: 970, logZ: -4685.75873\n",
      "training iter: 980, logZ: -4668.76141\n",
      "training iter: 990, logZ: -4835.12407\n",
      "training iter: 1000, logZ: -4649.38592\n"
     ]
    }
   ],
   "source": [
    "# number of GP layers\n",
    "nolayers = 2\n",
    "# number of hidden dimension in intermediate hidden layers\n",
    "n_hiddens = [3]\n",
    "# number of inducing points per layer\n",
    "M = 50\n",
    "n_pseudos = [M for _ in range(nolayers)]\n",
    "\n",
    "no_iterations = 1000\n",
    "no_points_per_mb = 500\n",
    "\n",
    "# We construct the network\n",
    "net = AEPDGP_net.AEPDGP_net(X, Y, n_hiddens, n_pseudos)\n",
    "t0 = time.time()\n",
    "# train\n",
    "test_nll, test_rms, energy = net.train(no_iterations=no_iterations,\n",
    "                               no_points_per_mb=no_points_per_mb,\n",
    "                               lrate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  2071.75235605\n",
      "test rmse:  0.0853715558013\n",
      "test log-likelihood:  1.05178101939\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print 'time: ', t1 - t0\n",
    "\n",
    "# We make predictions for the test set\n",
    "m, v = net.predict(Xs)\n",
    "\n",
    "# We compute the test RMSE\n",
    "rmse = np.sqrt(np.mean((Ys - m)**2))\n",
    "print 'test rmse: ', rmse\n",
    "\n",
    "# We compute the test log-likelihood\n",
    "test_ll = np.mean(-0.5 * np.log(2 * math.pi * (v)) - \\\n",
    "    0.5 * (Ys - m)**2 / (v))\n",
    "print 'test log-likelihood: ', test_ll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
